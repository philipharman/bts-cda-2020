{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aB_ck5OSE3TU"
   },
   "source": [
    "![BTS](https://github.com/vfp1/bts-mbds-data-science-foundations-2019/raw/master/sessions/img/Logo-BTS.jpg)\n",
    "\n",
    "# Session 5: Support Vector Machines\n",
    "\n",
    "### Victor F. Pajuelo Madrigal <victor.pajuelo@bts.tech> - Classical Data Analysis (16-02-2021)\n",
    "\n",
    "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vfp1/bts-mbds-classical-data-analysis-2019/blob/master/05_SVM/Session_5_Classical_Data_Analysis_SVM.ipynb)\n",
    "\n",
    "**Resources (code patched and updated from):**\n",
    "* MNIST\n",
    "* Sklearn\n",
    "* Aurelien Geron's O'Reilly's \"Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow\"\n",
    "* Lazy Programmer Lecture Series\n",
    "* Andrew Ng Lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHeWc1e1EKAP"
   },
   "source": [
    "# SVM gentle introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-6Oll67oFdp"
   },
   "source": [
    "## SVM - Image Clasification\n",
    "The UUID is **#S5C1**. You can use it to refer to the slides in Session 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DI19glDjpa9V"
   },
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z69BnrymoCWW"
   },
   "outputs": [],
   "source": [
    "# SVM is used within sklearn as Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "KMhh3FeOpQum",
    "outputId": "cc0197b2-1d67-40f7-e665-6cb5a5cf3d5f"
   },
   "outputs": [],
   "source": [
    "# Let's import MNIST directly from keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load data using keras mnist utils\n",
    "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R-oTIaG0sSSt",
    "outputId": "e3d3a7f3-85a4-4b04-f7ac-b5ea921c158f"
   },
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "print(train_X.shape, train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "Hs-Q013gszqJ",
    "outputId": "56da34f3-02c3-453e-838f-309cdafeb738"
   },
   "outputs": [],
   "source": [
    "# Exploring the dataset visually\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_X[0])\n",
    "plt.title(\" Digit \" + str(train_Y[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8qOLNv8otrVP",
    "outputId": "092175c4-de35-4aa0-97a2-3f90e6390b99"
   },
   "outputs": [],
   "source": [
    "# Checking the value range over the dataset\n",
    "\n",
    "# Check values for row 6, column 6\n",
    "train_X[6][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1wGho0s3uFGW",
    "outputId": "069ca8a6-d3ac-4977-846b-29633a8cf54a"
   },
   "outputs": [],
   "source": [
    "# Let's normalize the input so that SVM can perform better\n",
    "\n",
    "# First we need to flatten the images. We can use numpy reshape for that\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\n",
    "\n",
    "import numpy as np\n",
    "type(train_X)\n",
    "\n",
    "# Find size of one-dimensional vector for each image. Yes, it is 784\n",
    "num_pixels = train_X.shape[1] * train_X.shape[2] # find size of one-dimensional vector\n",
    "print(num_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "otvBBUFIyYtm",
    "outputId": "5a0505c7-3ff1-4b95-fd38-26288a64ebba"
   },
   "outputs": [],
   "source": [
    "# Now, let's flatten Train and Test images using numpy reshape\n",
    "train_X_reshaped = train_X.reshape(train_X.shape[0], num_pixels).astype('float32') \n",
    "test_X_reshaped = test_X.reshape(test_X.shape[0], num_pixels).astype('float32') \n",
    "\n",
    "print(train_X_reshaped.shape, test_X_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNew0i9ZzK7s"
   },
   "outputs": [],
   "source": [
    "# Now let's normalize the values from (0..255) to (0..1)\n",
    "\n",
    "train_X_normalized = train_X_reshaped / 255\n",
    "test_X_normalized = test_X_reshaped / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "1Tpp7QBZzfC5",
    "outputId": "7df810e0-7b71-43c7-842c-87d10622a762"
   },
   "outputs": [],
   "source": [
    "# Now let's test the values of array\n",
    "train_X_normalized[0][100:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LGDKkGyqCXT"
   },
   "source": [
    "#### Alternative: mean=0, variance=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_Tt8REaqIAZ"
   },
   "outputs": [],
   "source": [
    "# Let's apply sklearns mean=0, variance=1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_X_meanvar = scaler.fit_transform(train_X_reshaped)\n",
    "test_X_meanvar = scaler.transform(test_X_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "HkEwJh2JrdlX",
    "outputId": "06f0463c-c836-4174-fd16-59c09c279a3f"
   },
   "outputs": [],
   "source": [
    "# Now let's test the values of array\n",
    "train_X_meanvar[0][100:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "in43IAPrpiZq"
   },
   "source": [
    "### Fit the SVC\n",
    "\n",
    "**Be careful!** Train duration on Google Colab: 0:16:05.266673 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlGSFyElp_Ul"
   },
   "outputs": [],
   "source": [
    "# Call the SVC model\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "BNYpaulIqG6o",
    "outputId": "357fa710-31da-46a0-d56e-3ad41d1ba404"
   },
   "outputs": [],
   "source": [
    "t0 = datetime.now()\n",
    "model.fit(train_X_normalized, train_Y)\n",
    "print(\"Train duration:\", datetime.now()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzeTGrgFpk2C"
   },
   "source": [
    "### Evaluate the SVC\n",
    "\n",
    "**Be careful!** Train score on Google Colab: \n",
    "\n",
    "*   Train score duration on Google Colab:  0:27:02.376792 !!\n",
    "*   Test score duration on Google Colab:  0:04:25.458038 !!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H9WHwVdI0WBR",
    "outputId": "3e2b7a9e-45b9-4e12-d1be-ddf89f083955"
   },
   "outputs": [],
   "source": [
    "# The model score returns the accuracy\n",
    "t0 = datetime.now()\n",
    "print(\"Train score:\", model.score(train_X_normalized, train_Y), \"duration: \", datetime.now()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ka9W8bwd0tik",
    "outputId": "08fd338e-4f4f-4284-9cf5-672b7ec2c4f4"
   },
   "outputs": [],
   "source": [
    "# The model score returns the accuracy\n",
    "t0 = datetime.now()\n",
    "print(\"Test score:\", model.score(test_X_normalized, test_Y), \"duration: \", datetime.now()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tYRxzZhAOVkn"
   },
   "source": [
    "## SVM - Spam classifier\n",
    "\n",
    "The UUID is **#S5C2**. You can use it to refer to the slides in Session 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Km7kwdBPnIm"
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "Orb23U_x1EIp",
    "outputId": "c92346c2-c02c-4018-d5f0-ecfa430ced35"
   },
   "outputs": [],
   "source": [
    "# The dataset in the course repo is directly downloaded from Kaggle\n",
    "\n",
    "!wget \"https://github.com/vfp1/bts-mbds-classical-data-analysis-2019/raw/master/05_SVM/data/spam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_m27o0YQra0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "We need to define a particular encoding, because the original file contain invalid characters.\n",
    "So depending on your Pandas, an error can be thrown such as:\n",
    "\n",
    "UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 135-136: invalid continuation byte\n",
    "\n",
    "Usually, when working with text, you will find this issues scattered around. Since nowadays we \n",
    "tend to use emojis, symbols and other stuff which is not recognized by utf-8\n",
    "\"\"\"\n",
    "df_spam = pd.read_csv('data/spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "1vV8xYihRvcf",
    "outputId": "b7ed07ed-bd44-4b3a-c079-85ab03ed18f0"
   },
   "outputs": [],
   "source": [
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "wb2WtzCdR9rL",
    "outputId": "321f2e33-c519-496d-9ce4-711ca5dbaa10"
   },
   "outputs": [],
   "source": [
    "# Let's drop the columns that are not useful\n",
    "\n",
    "df_spam = df_spam.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sENE4qvOSP0G",
    "outputId": "770df0d0-8ae2-4aef-a6a2-5ec83e308ca8"
   },
   "outputs": [],
   "source": [
    "# Let's also rename the columns so we have something better than \"v1\" and \"v2\"\n",
    "\n",
    "df_spam.columns = ['labels', 'data']\n",
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouhLlDdz13jB"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "t1GVFp9cyp5y",
    "outputId": "598a968c-f49e-422e-b581-1d3123615630"
   },
   "outputs": [],
   "source": [
    "# Let's create a column for binary labels \n",
    "df_spam['binary_labels'] = df_spam['labels'].map({'ham':0, 'spam':1})\n",
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XpoaQG2z0kNr",
    "outputId": "53fee94f-818e-4369-e0ef-7564dfbf3672"
   },
   "outputs": [],
   "source": [
    "# Let's create our \"Y\" matrix by extracting our numpy array\n",
    "\n",
    "\"\"\"\n",
    "We really don't need to do this, as Sklearn accepts strings and series as labels.\n",
    "In any case, it is good practice to do this, as we have a numerical representation\n",
    "of the data in case that we want to build our own model.\n",
    "\"\"\"\n",
    "\n",
    "Y = df_spam['binary_labels'].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "op_Ll7p61xBC"
   },
   "outputs": [],
   "source": [
    "# Now let's create our \"X\" matrix, our input features for every sample\n",
    "\n",
    "\"\"\"\n",
    "Here we can use different approaches for our input matrix, whether that is TF-IDF\n",
    "or CountVectorizer which does basically raw counts.\n",
    "\n",
    "Here is the TF-IDF version\n",
    "\n",
    "We need to use the decode error to ignore invalid utf-8 characters\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(decode_error='ignore')\n",
    "X_tfidf = tfidf.fit_transform(df_spam['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20GlsZCB592b"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we can use different approaches for our input matrix, whether that is TF-IDF\n",
    "or CountVectorizer which does basically raw counts.\n",
    "\n",
    "Here is the CountVectorizer version\n",
    "\n",
    "We need to use the decode error to ignore invalid utf-8 characters\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(decode_error='ignore')\n",
    "X_rawcount = count_vectorizer.fit_transform(df_spam['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GjPvCIy7Ifd"
   },
   "outputs": [],
   "source": [
    "# Let's create the datasets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain_tfidf, Xtest_tfidf, Ytrain_tfidf, Ytest_tfidf = train_test_split(X_tfidf, Y, test_size=0.2)\n",
    "Xtrain_rawcount, Xtest_rawcount, Ytrain_rawcount, Ytest_rawcount = train_test_split(X_rawcount, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W8st0g4EIiTx",
    "outputId": "ee97b7eb-ac86-4686-8144-b61d51ce85a6"
   },
   "outputs": [],
   "source": [
    "Xtrain_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abYxqMAMPpeN"
   },
   "outputs": [],
   "source": [
    "#tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ToIoGKsuL9fc"
   },
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwWJqZ-oKbKb"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's create a function to visualize our data in a word cloud\n",
    "\n",
    "# We create our function that asks for a label\n",
    "def visualize(label):\n",
    "\n",
    "    # We initialize a \"words\" string\n",
    "    words = ''\n",
    "\n",
    "    # Loop through the DF, pass every message ('data') that has the same label noted in the string above\n",
    "    for msg in df_spam[df_spam['labels'] == label]['data']:\n",
    "        \n",
    "        # Convert the message to lowercase\n",
    "        msg = msg.lower()\n",
    "        \n",
    "        # Append the message to the words string and add a space\n",
    "        words += msg + ' '\n",
    "\n",
    "    # Generate a WordCloud with all the looped words\n",
    "    wordcloud = WordCloud(width=600, height=400).generate(words)\n",
    "\n",
    "    # Show the wordcloud with plt.imshow\n",
    "    plt.imshow(wordcloud)\n",
    "\n",
    "    # Take the axis off\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Set a title with the label\n",
    "    plt.title(label)\n",
    "\n",
    "    # Show the image\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "oKVfxWeEW4Me",
    "outputId": "09e22fb4-4fe0-4e1c-a188-ea88016e4a79"
   },
   "outputs": [],
   "source": [
    "visualize('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "zFNAhyv-W51T",
    "outputId": "e02560ef-87dc-409f-9d7d-e48207a3ca7a"
   },
   "outputs": [],
   "source": [
    "visualize('ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DivE3XDeINeP"
   },
   "source": [
    "### Fit the SVC for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmohT-AxF571"
   },
   "outputs": [],
   "source": [
    "# Let's fit the SVC model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# We will see what C stands for in next examples\n",
    "model_tfidf = SVC(kernel='linear', C=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xZluC32MKSIh",
    "outputId": "5f256eae-1cf4-4eb6-8f0e-c50c58cf4221"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This time training the SVM is way faster, because we have less data. And it is also\n",
    "just vectorized strings\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "t0 = datetime.now()\n",
    "model_tfidf.fit(Xtrain_tfidf, Ytrain_tfidf)\n",
    "print(\"train duration:\", datetime.now() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0mIEXHILx4a"
   },
   "source": [
    "### Evaluate the SVC for TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "f25_-fh9KWzk",
    "outputId": "5b3176c3-bde3-49ef-b2a7-ac0cdfae30da"
   },
   "outputs": [],
   "source": [
    "t0 = datetime.now()\n",
    "print(\"train score:\", model_tfidf.score(Xtrain_tfidf, Ytrain_tfidf), \"duration:\", datetime.now() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U9Om1KDIKY2v",
    "outputId": "b3b1915d-9691-493a-f231-953c1885d8bf"
   },
   "outputs": [],
   "source": [
    "t0 = datetime.now()\n",
    "print(\"test score:\", model_tfidf.score(Xtest_tfidf, Ytest_tfidf), \"duration:\", datetime.now() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJwACIMrWa91"
   },
   "source": [
    "### Fit the SVC for Raw Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWS29GbzbAnD"
   },
   "outputs": [],
   "source": [
    "# Let's fit the SVC model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# We will see what C stands for in next examples\n",
    "model_rawcount = SVC(kernel='linear', C=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eZPTKRKKWa-D",
    "outputId": "faeb1425-8e10-4c69-f96f-ebc29ba65efe"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This time training the SVM is way faster, because we have less data. And it is also\n",
    "just vectorized strings\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "t0 = datetime.now()\n",
    "model_rawcount.fit(Xtrain_rawcount, Ytrain_rawcount)\n",
    "print(\"train duration:\", datetime.now() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwb730McWa-H"
   },
   "source": [
    "### Evaluate the SVC for Raw Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6q8jey2QWa-I",
    "outputId": "7fd5553e-eeb2-489e-deda-f723b34e9ab5"
   },
   "outputs": [],
   "source": [
    "t0 = datetime.now()\n",
    "print(\"train score:\", model_rawcount.score(Xtrain_rawcount, Ytrain_rawcount), \"duration:\", datetime.now() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "twb2jq4lWa-M",
    "outputId": "4e481eb0-57c9-4023-8f44-5f8410b21c04"
   },
   "outputs": [],
   "source": [
    "t0 = datetime.now()\n",
    "print(\"test score:\", model_rawcount.score(Xtest_rawcount, Ytest_rawcount), \"duration:\", datetime.now() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LceshfWdW_fA"
   },
   "source": [
    "### Predictions\n",
    "\n",
    "We can dive a little bit deeper in that accuracy and see what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "IUAr0K3JKdZP",
    "outputId": "3973e1ea-9eff-417f-b912-ca91ecef119c"
   },
   "outputs": [],
   "source": [
    "# We are getting close to 100% accuracy in TF-IDF, but let's see what is wrong with our model\n",
    "df_spam['predictions'] = model_tfidf.predict(X_tfidf)\n",
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "40hCx40AKfJI",
    "outputId": "6da51cbc-7524-4689-87e9-426760b54bad"
   },
   "outputs": [],
   "source": [
    "# Let's look at things that should be spam\n",
    "print(\"*** things that should be spam ***\")\n",
    "\n",
    "# We filter the dataframe with elementwise AND operation to check when pred=0 but labels=1\n",
    "sneaky_spam = df_spam[(df_spam['predictions'] == 0) & (df_spam['binary_labels'] == 1)]['data']\n",
    "\n",
    "# We loop through each message in sneaky_spam and check messages that should have been spam (FALSE NEGATIVES)\n",
    "for msg in sneaky_spam:\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xZhpeJwqKhmq",
    "outputId": "57c5a270-20ed-4089-9e56-125517d3722e"
   },
   "outputs": [],
   "source": [
    "# Let's look at things that should be spam\n",
    "print(\"*** things that should be spam ***\")\n",
    "\n",
    "# We filter the dataframe with elementwise AND operation to check when pred=1 but labels=0\n",
    "sneaky_spam = df_spam[(df_spam['predictions'] == 1) & (df_spam['binary_labels'] == 0)]['data']\n",
    "\n",
    "# We loop through each message in sneaky_spam and check messages that should have been spam (FALSE POSITIVES)\n",
    "for msg in sneaky_spam:\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oAPeYEgBeVDm"
   },
   "source": [
    "### Let's plot PR curves, we need to update sklern to version 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jlhr56NheMKd",
    "outputId": "a8738f80-2c5d-49f6-e9d5-69648a83564f"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "_0cSWMJDeo7U",
    "outputId": "c237f2f0-0ed3-4358-e01a-0fddacc44f43"
   },
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zATk9mbFeuCR",
    "outputId": "aaaee780-eae1-4e60-83e3-8e889e03cac7"
   },
   "outputs": [],
   "source": [
    "# In Google Colab, we need to restart the kernel in order for this to take effect\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "PXfmDP22cHFi",
    "outputId": "57a5893f-3b8a-455c-bedc-cc09a91e1ddf"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = plot_precision_recall_curve(model_tfidf, Xtest_tfidf, Ytest_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "myoUM8sSfLdJ",
    "outputId": "1b074e63-dc1c-4b83-aaf5-defec38a6890"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = plot_precision_recall_curve(model_rawcount, Xtest_rawcount, Ytest_rawcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jQivk-3gNQ3"
   },
   "source": [
    "## SVM - Medical diagnosis\n",
    "\n",
    "The UUID is **#S5C3**. You can use it to refer to the slides in Session 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bd-lkLVyBuoM"
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wU0Qi3LvgaC4"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the brest cancer dataset\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6PiaJXVqFZ1b",
    "outputId": "5b37bda0-c7f0-444e-c808-b64d5f611ead"
   },
   "outputs": [],
   "source": [
    "# As stated, we get 569 instances and 30 features or attributes\n",
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "knWDaUb1FoSy",
    "outputId": "113c8f59-ec24-4e6c-e3c2-4cb8f12bae9c"
   },
   "outputs": [],
   "source": [
    "# The description of the dataset is associated with it\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQW_nydzB1JU"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzL1VRgo74Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(data.data, data.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7n5j12S_766h"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# The StandardScaler scales real value variables\n",
    "\n",
    "\"\"\"\n",
    "The standarization is done by removing the mean and scaling to unit variance.\n",
    "\n",
    "The standardized score of a sample \"X\" is calculated as:\n",
    "\n",
    "z = (x - u)/s\n",
    "\n",
    "    * u : the mean of the training samples\n",
    "    * s : standard deviation\n",
    "\"\"\"\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNV35zKfB4Gr"
   },
   "source": [
    "### Fit the SVC - linear kernel\n",
    "\n",
    "Check the slides related with **#S5C3** for more information on kernel functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "0jB3y1nY7-MQ",
    "outputId": "1292d137-aea9-4a69-a11c-4ced29cffae8"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Even if we are not experts at breast cancer detection, the beauty of machine learning\n",
    "is that we can extract information from the data even if we are not doctors. \n",
    "It doens't matter what the data is, it does not affect how the algorithm works.\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "# model = SVC()\n",
    "model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6OLOwlBCY9G"
   },
   "source": [
    "### Evaluate the SVC - linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xBzBityiCp0C",
    "outputId": "dbc16ee5-cc13-4987-ea41-400e11a6c8bf"
   },
   "outputs": [],
   "source": [
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6S16SDoSztt"
   },
   "source": [
    "### Fit the SVC - default RBF kernel\n",
    "\n",
    "Check the slides related with **#S5C3** for more information on kernel functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "xRXfJ7vhSztw",
    "outputId": "a46b3a88-63ec-4292-8ad8-ddf6475a71bd"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Even if we are not experts at breast cancer detection, the beauty of machine learning\n",
    "is that we can extract information from the data even if we are not doctors. \n",
    "It doens't matter what the data is, it does not affect how the algorithm works.\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "# model = SVC()\n",
    "model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgVFpaFgSzt2"
   },
   "source": [
    "### Evaluate the SVC - default RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nRN_UoBESzt3",
    "outputId": "473406a1-e21b-4591-cb4b-60f312fdce9c"
   },
   "outputs": [],
   "source": [
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KsSDDLQ5TL9M"
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "A linear model is good enough so a non-linear model is not needed. As a reminder, just because you can use a more expressive model (non-linear) you don't need to use it. Sometimes, linear models are good enough generalizers and faster to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKOdqWFuaEDV"
   },
   "source": [
    "## SVM - Concrete regression\n",
    "\n",
    "The UUID is **#S5C4**. You can use it to refer to the slides in Session 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-BW6IsGc3jr"
   },
   "source": [
    "### Download and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "5Jt4ojInSsGy",
    "outputId": "ce2400f3-11be-4d70-d560-38a810c8e30c"
   },
   "outputs": [],
   "source": [
    "#!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "EkLAJBNtaOwL",
    "outputId": "d1b26e46-b03c-45f5-a4d8-76b4fa33f0f0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('data/Concrete_Data.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhXLQUSmc6iP"
   },
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "5Opkcm5PaV1-",
    "outputId": "201613db-e70f-46cb-ba2f-85b86966138e"
   },
   "outputs": [],
   "source": [
    "# We take out those crazy titles and pass the number of each column\n",
    "df.columns = list(range(df.shape[1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dAS_HcwVaiDr"
   },
   "outputs": [],
   "source": [
    "# We load the column values as numpy array\n",
    "# Column 8 is the compressive strenght, the target\n",
    "X = df[[0,1,2,3,4,5,6,7]].values\n",
    "Y = df[8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bTjkHa8pakAG",
    "outputId": "9e214d9e-967e-45ba-d4d2-6ff5007032ee"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.33)\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXoBzTsAeKoH"
   },
   "source": [
    "We standardize both input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hpdz_z_ZamIn"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bNO2Sji4e6EQ",
    "outputId": "3102072b-8a26-4847-e5f7-955c414b0088"
   },
   "outputs": [],
   "source": [
    "# For the target, this will through an error because expects 2D array and target is 1D\n",
    "target_scaler = StandardScaler()\n",
    "Ytrain = target_scaler.fit_transform(Ytrain)\n",
    "Ytest = target_scaler.transform(Ytest)\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KCqITUHoaoVt",
    "outputId": "10d3ca8d-6729-4e5a-c23d-5590e7158ffd"
   },
   "outputs": [],
   "source": [
    "# This is the correct way to do it\n",
    "target_scaler = StandardScaler()\n",
    "Ytrain = target_scaler.fit_transform(Ytrain.reshape(-1, 1)).flatten()\n",
    "Ytest = target_scaler.transform(Ytest.reshape(-1, 1)).flatten()\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmCq4bZUePCT"
   },
   "source": [
    "We use here the **SVR** which is the SVM that Sklearn uses for regression. We will use different kernels and see how **rbf** is actually the best one that we can apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7TPhH5zZaxp7",
    "outputId": "5c35025a-2f99-491f-f239-fb01998632c7"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='linear')\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "P9F9C9yea4mZ",
    "outputId": "0f26c919-beac-45e2-8ef5-75a04e761456"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='poly')\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HplqARtibK6u",
    "outputId": "bf3a109e-9bd3-4464-d0d0-1be3fa3fb6bd"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EsqrIHLavnQ"
   },
   "source": [
    "# SVM Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9X1SSoaOm5W"
   },
   "source": [
    "##  Setup\n",
    "\n",
    "Following Aurelien Geron's suggestion, let's set up the working environment in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "96UJTdfWOvsi",
    "outputId": "4982ec60-6ddc-4ddf-f8b1-f75b63494559"
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "# Let's assert that that is the case\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6ogJIkAHTzSj",
    "outputId": "322f51f8-269d-4ee4-a87d-4e4f2f4638ad"
   },
   "outputs": [],
   "source": [
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EIfzq-6ULxQ"
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9peJ1HPCUPFF"
   },
   "outputs": [],
   "source": [
    "# This will make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rb60GTf6UW3D"
   },
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzNDSkgmUcDS"
   },
   "outputs": [],
   "source": [
    "# Where to save the figures (adjust this to your convenience)\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"svm\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wNR9zAXUnkV"
   },
   "outputs": [],
   "source": [
    "# A function to save our figures\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5ZVd0m9a1Az"
   },
   "source": [
    "## Linear SVM - Large Margin Classification\n",
    "\n",
    "The UUID is **#S5C5**. You can use it to refer to the slides in Session 5.\n",
    "\n",
    "This code reproduces the images from the slides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7lj8AitfYaqL"
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "37NqjuYjbRu-",
    "outputId": "2ef084e6-97e8-47a5-b318-e355a5e7970f"
   },
   "outputs": [],
   "source": [
    "# Import SVC and datasets from sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnMYJ31PVVob"
   },
   "outputs": [],
   "source": [
    "# Choose the data we need to work with\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]\n",
    "\n",
    "\"\"\"\n",
    "The pipe argument \"|\" is a bitwise OR of integers, meaning that it will be true\n",
    "when y==0 and y==1. This creates a boolean matrix with the values to index for \n",
    "X and y\n",
    "\"\"\"\n",
    "setosa_or_versicolor = (y == 0) | (y == 1)\n",
    "X = X[setosa_or_versicolor]\n",
    "y = y[setosa_or_versicolor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "EjvWl2R3XUr9",
    "outputId": "1b04bd31-dea3-4f17-fcf5-0acd7fdd053a"
   },
   "outputs": [],
   "source": [
    "# SVM Classifier model\n",
    "# The kernel is set to linear and C to inf\n",
    "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"))\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jbj75UxaYeZd"
   },
   "source": [
    "### Fake linear regressors and SVMs\n",
    "\n",
    "The UUID is **#S5C5**. You can use it to refer to the slides in Session 5.\n",
    "\n",
    "This code reproduces the images from the slides.\n",
    "\n",
    "This code reproduces the fake linear regressors explored in the slides as well as the Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kb3FW2IcoFMo"
   },
   "outputs": [],
   "source": [
    "# Generation of bad models\n",
    "# Generation of x data with linspace (evenly spaced numbers over start, stop, number of numbers)\n",
    "x0 = np.linspace(0, 5.5, 200)\n",
    "# Y=5*x0 -20\n",
    "pred_1 = 5*x0 - 20\n",
    "# Y=1*x0 -1.8\n",
    "pred_2 = x0 - 1.8\n",
    "# Y=0.1*x0 + 0.5\n",
    "pred_3 = 0.1 * x0 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oPl13tUApO2u",
    "outputId": "21bf2937-aa04-43df-8660-3a189fbd1886"
   },
   "outputs": [],
   "source": [
    "svm_clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_l3-phboGzd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generation of function to plot SVM decision boundaries\n",
    "def plot_svc_decision_boundary(svm_clf, xmin, xmax):\n",
    "    # Take the weights from the SVM fitted above\n",
    "    w = svm_clf.coef_[0]\n",
    "    # Take the bias from the SVM fitted above\n",
    "    b = svm_clf.intercept_[0]\n",
    "\n",
    "    \"\"\"\n",
    "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
    "    # => x1 = -w0/w1 * x0 - b/w1\n",
    "    \"\"\"\n",
    "    x0 = np.linspace(xmin, xmax, 200)\n",
    "    decision_boundary = -w[0]/w[1] * x0 - b/w[1]\n",
    "\n",
    "    # This is half margin, the lenght of full margin is 2/w[1]\n",
    "    margin = 1/w[1]\n",
    "    gutter_up = decision_boundary + margin\n",
    "    gutter_down = decision_boundary - margin\n",
    "\n",
    "    # Plot the support vectors\n",
    "    svs = svm_clf.support_vectors_\n",
    "    # Plot the scatter support vectors\n",
    "    plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors='#FFAAAA')\n",
    "    # Plot the decision boundary, upper and lower gutter\n",
    "    plt.plot(x0, decision_boundary, \"k-\", linewidth=2)\n",
    "    plt.plot(x0, gutter_up, \"k--\", linewidth=2)\n",
    "    plt.plot(x0, gutter_down, \"k--\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "ZSvMEFSaY1od",
    "outputId": "85d0edf7-7277-4076-a669-6edfb485a4b2"
   },
   "outputs": [],
   "source": [
    "# Generation of plots\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10,2.7), sharey=True)\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.plot(x0, pred_1, \"g--\", linewidth=2)\n",
    "plt.plot(x0, pred_2, \"m-\", linewidth=2)\n",
    "plt.plot(x0, pred_3, \"r-\", linewidth=2)\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([0, 5.5, 0, 2])\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_svc_decision_boundary(svm_clf, 0, 5.5)\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.axis([0, 5.5, 0, 2])\n",
    "\n",
    "save_fig(\"large_margin_classification_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCpVX2xiA8we"
   },
   "source": [
    "## Sensitivity to feature scales\n",
    "\n",
    "The UUID is **#S5C6**. You can use it to refer to the slides in Session 5.\n",
    "\n",
    "Here we show that the scale it is extremely important for SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVdFb77yBcnu"
   },
   "source": [
    "### Create some fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ja13Ybd0BfLZ"
   },
   "outputs": [],
   "source": [
    "Xs = np.array([[1, 50], [5, 20], [3, 80], [5, 60]]).astype(np.float64)\n",
    "ys = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x9djxDI5Bg2v"
   },
   "source": [
    "### Fit the SVM without scaling the data\n",
    "\n",
    "We tweak the \"C\" parameter, we will see soon for what we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "s6UXNheAB8M7",
    "outputId": "cf3d5be0-5760-4e91-b65f-6d33249fdc93"
   },
   "outputs": [],
   "source": [
    "svm_clf_unscaled = SVC(kernel=\"linear\", C=100)\n",
    "svm_clf_unscaled.fit(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcqLLdYrCIku"
   },
   "source": [
    "### Fit the SVM scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "0Jk1CegjCK_T",
    "outputId": "727e47c4-ed5b-47f4-ee0e-6bd81cd535b3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(Xs)\n",
    "\n",
    "svm_clf_scaled = SVC(kernel=\"linear\", C=100)\n",
    "svm_clf_scaled.fit(X_scaled, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fPbyDIdMCeUm"
   },
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "Wko87KjkCgGj",
    "outputId": "354278c3-fab3-45b6-8575-c05c158ee6e1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,2.7))\n",
    "plt.subplot(121)\n",
    "plt.plot(Xs[:, 0][ys==1], Xs[:, 1][ys==1], \"bo\")\n",
    "plt.plot(Xs[:, 0][ys==0], Xs[:, 1][ys==0], \"ms\")\n",
    "plot_svc_decision_boundary(svm_clf_unscaled, 0, 6)\n",
    "plt.xlabel(\"$x_0$\", fontsize=20)\n",
    "plt.ylabel(\"$x_1$    \", fontsize=20, rotation=0)\n",
    "plt.title(\"Unscaled\", fontsize=16)\n",
    "plt.axis([0, 6, 0, 90])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(X_scaled[:, 0][ys==1], X_scaled[:, 1][ys==1], \"bo\")\n",
    "plt.plot(X_scaled[:, 0][ys==0], X_scaled[:, 1][ys==0], \"ms\")\n",
    "plot_svc_decision_boundary(svm_clf_scaled, -2, 2)\n",
    "plt.xlabel(\"$x_0$\", fontsize=20)\n",
    "plt.ylabel(\"$x'_1$  \", fontsize=20, rotation=0)\n",
    "plt.title(\"Scaled\", fontsize=16)\n",
    "plt.axis([-2, 2, -2, 2])\n",
    "\n",
    "save_fig(\"sensitivity_to_feature_scales_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8_RkoxzFsF5"
   },
   "source": [
    "## Soft margin classification - outlier detection\n",
    "The UUID is **#S5C7**. You can use it to refer to the slides in Session 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "vky7A6GwClMg",
    "outputId": "42431c23-c84c-490c-bd13-03927960fde0"
   },
   "outputs": [],
   "source": [
    "X_outliers = np.array([[3.4, 1.3], [3.2, 0.8]])\n",
    "y_outliers = np.array([0, 0])\n",
    "Xo1 = np.concatenate([X, X_outliers[:1]], axis=0)\n",
    "yo1 = np.concatenate([y, y_outliers[:1]], axis=0)\n",
    "Xo2 = np.concatenate([X, X_outliers[1:]], axis=0)\n",
    "yo2 = np.concatenate([y, y_outliers[1:]], axis=0)\n",
    "\n",
    "svm_clf2 = SVC(kernel=\"linear\", C=10**9)\n",
    "svm_clf2.fit(Xo2, yo2)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10,2.7), sharey=True)\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.plot(Xo1[:, 0][yo1==1], Xo1[:, 1][yo1==1], \"bs\")\n",
    "plt.plot(Xo1[:, 0][yo1==0], Xo1[:, 1][yo1==0], \"yo\")\n",
    "plt.text(0.3, 1.0, \"Impossible!\", fontsize=24, color=\"red\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.annotate(\"Outlier\",\n",
    "             xy=(X_outliers[0][0], X_outliers[0][1]),\n",
    "             xytext=(2.5, 1.7),\n",
    "             ha=\"center\",\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1),\n",
    "             fontsize=16,\n",
    "            )\n",
    "plt.axis([0, 5.5, 0, 2])\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.plot(Xo2[:, 0][yo2==1], Xo2[:, 1][yo2==1], \"bs\")\n",
    "plt.plot(Xo2[:, 0][yo2==0], Xo2[:, 1][yo2==0], \"yo\")\n",
    "plot_svc_decision_boundary(svm_clf2, 0, 5.5)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.annotate(\"Outlier\",\n",
    "             xy=(X_outliers[1][0], X_outliers[1][1]),\n",
    "             xytext=(3.2, 0.08),\n",
    "             ha=\"center\",\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1),\n",
    "             fontsize=16,\n",
    "            )\n",
    "plt.axis([0, 5.5, 0, 2])\n",
    "\n",
    "save_fig(\"sensitivity_to_outliers_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70HiOd2EakSr"
   },
   "source": [
    "## Outliers and hyperparameter C\n",
    "\n",
    "The UUID is **#S5C8**. You can use it to refer to the slides in Session 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UapmR3piakSs"
   },
   "source": [
    "This is the first code example in chapter 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "1s_YYzw4akSt",
    "outputId": "05f21f34-2682-4ce4-8a59-66364a420ea4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.float64)  # Iris virginica\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", random_state=42)),\n",
    "    ])\n",
    "\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k2cQ2bBiakSw",
    "outputId": "123b81f1-6e8b-4397-fbb2-fda40d68e9d7"
   },
   "outputs": [],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AonqkXLsakSz"
   },
   "source": [
    "Now let's generate the graph comparing different regularization settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "A5mlBv73akS0",
    "outputId": "778de10a-336f-464f-fb5b-351a91ccac3a"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "svm_clf1 = LinearSVC(C=1, loss=\"hinge\", random_state=42)\n",
    "svm_clf2 = LinearSVC(C=100, loss=\"hinge\", random_state=42)\n",
    "\n",
    "scaled_svm_clf1 = Pipeline([\n",
    "        (\"scaler\", scaler),\n",
    "        (\"linear_svc\", svm_clf1),\n",
    "    ])\n",
    "scaled_svm_clf2 = Pipeline([\n",
    "        (\"scaler\", scaler),\n",
    "        (\"linear_svc\", svm_clf2),\n",
    "    ])\n",
    "\n",
    "scaled_svm_clf1.fit(X, y)\n",
    "scaled_svm_clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q30beii5akS3"
   },
   "outputs": [],
   "source": [
    "# Convert to unscaled parameters\n",
    "b1 = svm_clf1.decision_function([-scaler.mean_ / scaler.scale_])\n",
    "b2 = svm_clf2.decision_function([-scaler.mean_ / scaler.scale_])\n",
    "w1 = svm_clf1.coef_[0] / scaler.scale_\n",
    "w2 = svm_clf2.coef_[0] / scaler.scale_\n",
    "svm_clf1.intercept_ = np.array([b1])\n",
    "svm_clf2.intercept_ = np.array([b2])\n",
    "svm_clf1.coef_ = np.array([w1])\n",
    "svm_clf2.coef_ = np.array([w2])\n",
    "\n",
    "# Find support vectors (LinearSVC does not do this automatically)\n",
    "t = y * 2 - 1\n",
    "support_vectors_idx1 = (t * (X.dot(w1) + b1) < 1).ravel()\n",
    "support_vectors_idx2 = (t * (X.dot(w2) + b2) < 1).ravel()\n",
    "svm_clf1.support_vectors_ = X[support_vectors_idx1]\n",
    "svm_clf2.support_vectors_ = X[support_vectors_idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "_pA4ZjICakS6",
    "outputId": "6cf89161-757f-4c17-de9c-0e21f1b24738"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10,2.7), sharey=True)\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\", label=\"Iris virginica\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\", label=\"Iris versicolor\")\n",
    "plot_svc_decision_boundary(svm_clf1, 4, 5.9)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.title(\"$C = {}$\".format(svm_clf1.C), fontsize=16)\n",
    "plt.axis([4, 5.9, 0.8, 2.8])\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
    "plot_svc_decision_boundary(svm_clf2, 4, 5.99)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.title(\"$C = {}$\".format(svm_clf2.C), fontsize=16)\n",
    "plt.axis([4, 5.9, 0.8, 2.8])\n",
    "\n",
    "save_fig(\"regularization_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CqnuXp1akS9"
   },
   "source": [
    "## Non-linear classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ule3tFfwxjAr"
   },
   "source": [
    "### Polynomial expansion\n",
    "\n",
    "The UUID is **#S5C9**. You can use it to refer to the slides in Session 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "IiZ0SLq8akS-",
    "outputId": "5acdd10a-4d77-4f86-d532-f18067747dcf"
   },
   "outputs": [],
   "source": [
    "X1D = np.linspace(-4, 4, 9).reshape(-1, 1)\n",
    "X2D = np.c_[X1D, X1D**2]\n",
    "y = np.array([0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.grid(True, which='both')\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.plot(X1D[:, 0][y==0], np.zeros(4), \"bs\")\n",
    "plt.plot(X1D[:, 0][y==1], np.zeros(5), \"g^\")\n",
    "plt.gca().get_yaxis().set_ticks([])\n",
    "plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "plt.axis([-4.5, 4.5, -0.2, 0.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.grid(True, which='both')\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.axvline(x=0, color='k')\n",
    "plt.plot(X2D[:, 0][y==0], X2D[:, 1][y==0], \"bs\")\n",
    "plt.plot(X2D[:, 0][y==1], X2D[:, 1][y==1], \"g^\")\n",
    "plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "plt.ylabel(r\"$x_2$  \", fontsize=20, rotation=0)\n",
    "plt.gca().get_yaxis().set_ticks([0, 4, 8, 12, 16])\n",
    "plt.plot([-4.5, 4.5], [6.5, 6.5], \"r--\", linewidth=3)\n",
    "plt.axis([-4.5, 4.5, -1, 17])\n",
    "\n",
    "plt.subplots_adjust(right=1)\n",
    "\n",
    "save_fig(\"higher_dimensions_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "qHJfl6_vakTB",
    "outputId": "974008ab-c9eb-4411-f3aa-771523d55725"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
    "\n",
    "def plot_dataset(X, y, axes):\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n",
    "\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "WpNt01SoakTG",
    "outputId": "8e681905-e7ea-4e3d-bbc1-1af5e924bbc8"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", random_state=42))\n",
    "    ])\n",
    "\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "ZuzCNkIrakTJ",
    "outputId": "c81f4122-b2ef-40ea-da94-b1e6c9ba44ea"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(clf, axes):\n",
    "    x0s = np.linspace(axes[0], axes[1], 100)\n",
    "    x1s = np.linspace(axes[2], axes[3], 100)\n",
    "    x0, x1 = np.meshgrid(x0s, x1s)\n",
    "    X = np.c_[x0.ravel(), x1.ravel()]\n",
    "    y_pred = clf.predict(X).reshape(x0.shape)\n",
    "    y_decision = clf.decision_function(X).reshape(x0.shape)\n",
    "    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n",
    "    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n",
    "\n",
    "plot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "\n",
    "save_fig(\"moons_polynomial_svc_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWX_HBlMxrQt"
   },
   "source": [
    "### Kernel trick\n",
    "\n",
    "The UUID is **#S5C10**. You can use it to refer to the slides in Session 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "icqMAn1RakTN",
    "outputId": "b54937d6-840d-4edc-ed6b-528b9837efdb"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
    "    ])\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "wkqNZxKYakTQ",
    "outputId": "2276f767-7b0d-42fc-ffaf-d399417d8ae1"
   },
   "outputs": [],
   "source": [
    "poly100_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=10, coef0=100, C=5))\n",
    "    ])\n",
    "poly100_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "OARV9TkAakTT",
    "outputId": "b67a2e18-edbf-4e26-e994-1c5a9b18c886"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10.5, 4), sharey=True)\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_predictions(poly_kernel_svm_clf, [-1.5, 2.45, -1, 1.5])\n",
    "plot_dataset(X, y, [-1.5, 2.4, -1, 1.5])\n",
    "plt.title(r\"$d=3, r=1, C=5$\", fontsize=18)\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_predictions(poly100_kernel_svm_clf, [-1.5, 2.45, -1, 1.5])\n",
    "plot_dataset(X, y, [-1.5, 2.4, -1, 1.5])\n",
    "plt.title(r\"$d=10, r=100, C=5$\", fontsize=18)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "save_fig(\"moons_kernelized_polynomial_svc_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdLlZE2pakTn"
   },
   "source": [
    "## Regression with SVMs\n",
    "\n",
    "The UUID is **#S5C11**. You can use it to refer to the slides in Session 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kh0EfOSZakTo"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "m = 50\n",
    "X = 2 * np.random.rand(m, 1)\n",
    "y = (4 + 3 * X + np.random.randn(m, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Yavo9S1CakTr",
    "outputId": "8e778a9e-7e40-4c1b-8eff-74197fa24b5a"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg = LinearSVR(epsilon=1.5, random_state=42)\n",
    "svm_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXjvx80KakTu"
   },
   "outputs": [],
   "source": [
    "svm_reg1 = LinearSVR(epsilon=1.5, random_state=42)\n",
    "svm_reg2 = LinearSVR(epsilon=0.5, random_state=42)\n",
    "svm_reg1.fit(X, y)\n",
    "svm_reg2.fit(X, y)\n",
    "\n",
    "def find_support_vectors(svm_reg, X, y):\n",
    "    y_pred = svm_reg.predict(X)\n",
    "    off_margin = (np.abs(y - y_pred) >= svm_reg.epsilon)\n",
    "    return np.argwhere(off_margin)\n",
    "\n",
    "svm_reg1.support_ = find_support_vectors(svm_reg1, X, y)\n",
    "svm_reg2.support_ = find_support_vectors(svm_reg2, X, y)\n",
    "\n",
    "eps_x1 = 1\n",
    "eps_y_pred = svm_reg1.predict([[eps_x1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "GW7oimrkakT0",
    "outputId": "bea3fd45-2053-45c3-ac49-cd0b1b34906a"
   },
   "outputs": [],
   "source": [
    "def plot_svm_regression(svm_reg, X, y, axes):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100).reshape(100, 1)\n",
    "    y_pred = svm_reg.predict(x1s)\n",
    "    plt.plot(x1s, y_pred, \"k-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "    plt.plot(x1s, y_pred + svm_reg.epsilon, \"k--\")\n",
    "    plt.plot(x1s, y_pred - svm_reg.epsilon, \"k--\")\n",
    "    plt.scatter(X[svm_reg.support_], y[svm_reg.support_], s=180, facecolors='#FFAAAA')\n",
    "    plt.plot(X, y, \"bo\")\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.legend(loc=\"upper left\", fontsize=18)\n",
    "    plt.axis(axes)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(9, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plot_svm_regression(svm_reg1, X, y, [0, 2, 3, 11])\n",
    "plt.title(r\"$\\epsilon = {}$\".format(svm_reg1.epsilon), fontsize=18)\n",
    "plt.ylabel(r\"$y$\", fontsize=18, rotation=0)\n",
    "#plt.plot([eps_x1, eps_x1], [eps_y_pred, eps_y_pred - svm_reg1.epsilon], \"k-\", linewidth=2)\n",
    "plt.annotate(\n",
    "        '', xy=(eps_x1, eps_y_pred), xycoords='data',\n",
    "        xytext=(eps_x1, eps_y_pred - svm_reg1.epsilon),\n",
    "        textcoords='data', arrowprops={'arrowstyle': '<->', 'linewidth': 1.5}\n",
    "    )\n",
    "plt.text(0.91, 5.6, r\"$\\epsilon$\", fontsize=20)\n",
    "plt.sca(axes[1])\n",
    "plot_svm_regression(svm_reg2, X, y, [0, 2, 3, 11])\n",
    "plt.title(r\"$\\epsilon = {}$\".format(svm_reg2.epsilon), fontsize=18)\n",
    "save_fig(\"svm_regression_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNkjaRiqakT3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "m = 100\n",
    "X = 2 * np.random.rand(m, 1) - 1\n",
    "y = (0.2 + 0.1 * X + 0.5 * X**2 + np.random.randn(m, 1)/10).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tq9tP-DdakT6"
   },
   "source": [
    "**Note**: to be future-proof, we set `gamma=\"scale\"`, as this will be the default value in Scikit-Learn 0.22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mB6K_FE2akT7",
    "outputId": "5f28a513-99f3-4f8d-ee08-b19da536d542"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1, gamma=\"scale\")\n",
    "svm_poly_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gxCexml9akT-",
    "outputId": "ec7bfc4a-e943-44c9-c96d-88995eccbc56"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_poly_reg1 = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1, gamma=\"scale\")\n",
    "svm_poly_reg2 = SVR(kernel=\"poly\", degree=2, C=0.01, epsilon=0.1, gamma=\"scale\")\n",
    "svm_poly_reg1.fit(X, y)\n",
    "svm_poly_reg2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "i-1604m1akUB",
    "outputId": "cfc7414c-af1a-46a1-ca1a-7f16e21b846a"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(9, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plot_svm_regression(svm_poly_reg1, X, y, [-1, 1, 0, 1])\n",
    "plt.title(r\"$degree={}, C={}, \\epsilon = {}$\".format(svm_poly_reg1.degree, svm_poly_reg1.C, svm_poly_reg1.epsilon), fontsize=18)\n",
    "plt.ylabel(r\"$y$\", fontsize=18, rotation=0)\n",
    "plt.sca(axes[1])\n",
    "plot_svm_regression(svm_poly_reg2, X, y, [-1, 1, 0, 1])\n",
    "plt.title(r\"$degree={}, C={}, \\epsilon = {}$\".format(svm_poly_reg2.degree, svm_poly_reg2.C, svm_poly_reg2.epsilon), fontsize=18)\n",
    "save_fig(\"svm_with_polynomial_kernel_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-YHHEJVD40c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "c-6Oll67oFdp",
    "DI19glDjpa9V",
    "_jQivk-3gNQ3",
    "fKOdqWFuaEDV",
    "5EsqrIHLavnQ",
    "l9X1SSoaOm5W"
   ],
   "name": "Session_5_Classical_Data_Analysis_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
