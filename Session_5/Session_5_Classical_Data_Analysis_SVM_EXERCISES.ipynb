{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aB_ck5OSE3TU"
   },
   "source": [
    "![BTS](https://github.com/vfp1/bts-mbds-data-science-foundations-2019/raw/master/sessions/img/Logo-BTS.jpg)\n",
    "\n",
    "# Session 5: Support Vector Machines EXERCISES\n",
    "\n",
    "### Filipa Peleja <filipa.peleja@bts.tech>\n",
    "### Victor F. Pajuelo Madrigal <victor.pajuelo@bts.tech>\n",
    "\n",
    "## Classical Data Analysis (16-02-2021)\n",
    "\n",
    "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vfp1/bts-cda-2020/blob/master/Session_5/Session_5_Classical_Data_Analysis_SVM_EXERCISES.ipynb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9rDsHQd_aQQ"
   },
   "source": [
    "## Exercise one [NO CODE]\n",
    "\n",
    "1.   What is a support vector?\n",
    "> Support vectors are the datapoints used to determine the hyperplane and its margins. For a linearly seperable dataset, the support vectors should be the \"inner-most\" data points of the two classes. It is between these two data points that the hyerplane will be oriented with the maximum margin possible. \n",
    "2.   Why it is important to scale inputs when using the SVM?\n",
    "> Unscaled inputs can affect training time, but the biggest issue is that they affect model performance. Depending on what's being measured, unscaled inputs can have very different ranges of values (ex. *[Height, Weight, LDL Cholestorol Level]* to predict *[High risk of heart disease (y/n)]*). As a result, the weights applied to these unscaled inputs will have highly different values as well. Because the SVM cost function often uses an L2 penalty (which penalizes large weights), there is a tendency to drive some weights towards zero, while other weights are overinflated to reduce the overall loss. Scaling the inputs effectively scales the weights, which helps prevent disproportionate values being assigned to the weights.\n",
    "\n",
    "3. Should you use dual=True or dual=False when training a model with millions of samples but hundreds of features?\n",
    "> Dual = False, because there are more samples than features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "razi289oCbos"
   },
   "source": [
    "## Exercise two [NECESSARY]\n",
    "\n",
    "Train a SVM classifier on the datasets shown in class (not the regression one). Take special care with the hyperparameters for multiclassification, C and other hyperparameters that we discussed. You may want to tune the hyperparameters using smaller validation sets to speed up the process. What accuracy can you reach?\n",
    "\n",
    "In this exercise you need to:\n",
    "\n",
    "- Visualize and present the dataset\n",
    "- Apply the SVC to perform binary classification\n",
    "- Comment on the usage of the different kernels and the effect of the hyper-parameters (is always needed a nonlinear kernel?)\n",
    "- Visualize the results with a confusion matrix\n",
    "- Compute the accuracy score and comment on the results\n",
    "- Perform any other experiments that you can think of, always reason about the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load breast cancer data set\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Scale inputs\n",
    "scaler = StandardScaler()\n",
    "inputs_scaled = scaler.fit_transform(data.data)\n",
    "\n",
    "x = pd.DataFrame( data = inputs_scaled, columns = data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Train/test split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(x, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Input Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>-0.312589</td>\n",
       "      <td>-0.931027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>-0.217664</td>\n",
       "      <td>-1.058611</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>-0.809117</td>\n",
       "      <td>-0.895587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>2.137194</td>\n",
       "      <td>1.043695</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>-0.820070</td>\n",
       "      <td>-0.561032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0       1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
       "1       1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
       "2       1.579888      0.456187        1.566503   1.558884         0.942210   \n",
       "3      -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
       "4       1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     2.110995      0.721473        2.060786   2.343856         1.041842   \n",
       "565     1.704854      2.085134        1.615931   1.723842         0.102458   \n",
       "566     0.702284      2.045574        0.672676   0.577953        -0.840484   \n",
       "567     1.838341      2.336457        1.982524   1.735218         1.525767   \n",
       "568    -1.808401      1.221792       -1.814389  -1.347789        -3.112085   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            3.283515        2.652874             2.532475       2.217515   \n",
       "1           -0.487072       -0.023846             0.548144       0.001392   \n",
       "2            1.052926        1.363478             2.037231       0.939685   \n",
       "3            3.402909        1.915897             1.451707       2.867383   \n",
       "4            0.539340        1.371011             1.428493      -0.009560   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.219060        1.947285             2.320965      -0.312589   \n",
       "565         -0.017833        0.693043             1.263669      -0.217664   \n",
       "566         -0.038680        0.046588             0.105777      -0.809117   \n",
       "567          3.272144        3.296944             2.658866       2.137194   \n",
       "568         -1.150752       -1.114873            -1.261820      -0.820070   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                  2.255747  ...      1.886690      -1.359293   \n",
       "1                 -0.868652  ...      1.805927      -0.369203   \n",
       "2                 -0.398008  ...      1.511870      -0.023974   \n",
       "3                  4.910919  ...     -0.281464       0.133984   \n",
       "4                 -0.562450  ...      1.298575      -1.466770   \n",
       "..                      ...  ...           ...            ...   \n",
       "564               -0.931027  ...      1.901185       0.117700   \n",
       "565               -1.058611  ...      1.536720       2.047399   \n",
       "566               -0.895587  ...      0.561361       1.374854   \n",
       "567                1.043695  ...      1.961239       2.237926   \n",
       "568               -0.561032  ...     -1.410893       0.764190   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0           2.303601    2.001237          1.307686           2.616665   \n",
       "1           1.535126    1.890489         -0.375612          -0.430444   \n",
       "2           1.347475    1.456285          0.527407           1.082932   \n",
       "3          -0.249939   -0.550021          3.394275           3.893397   \n",
       "4           1.338539    1.220724          0.220556          -0.313395   \n",
       "..               ...         ...               ...                ...   \n",
       "564         1.752563    2.015301          0.378365          -0.273318   \n",
       "565         1.421940    1.494959         -0.691230          -0.394820   \n",
       "566         0.579001    0.427906         -0.809587           0.350735   \n",
       "567         2.303601    1.653171          1.430427           3.904848   \n",
       "568        -1.432735   -1.075813         -1.859019          -1.207552   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0           2.109526              2.296076        2.750622   \n",
       "1          -0.146749              1.087084       -0.243890   \n",
       "2           0.854974              1.955000        1.152255   \n",
       "3           1.989588              2.175786        6.046041   \n",
       "4           0.613179              0.729259       -0.868353   \n",
       "..               ...                   ...             ...   \n",
       "564         0.664512              1.629151       -1.360158   \n",
       "565         0.236573              0.733827       -0.531855   \n",
       "566         0.326767              0.414069       -1.104549   \n",
       "567         3.197605              2.289985        1.919083   \n",
       "568        -1.305831             -1.745063       -0.048138   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                   1.937015  \n",
       "1                   0.281190  \n",
       "2                   0.201391  \n",
       "3                   4.935010  \n",
       "4                  -0.397100  \n",
       "..                       ...  \n",
       "564                -0.709091  \n",
       "565                -0.973978  \n",
       "566                -0.318409  \n",
       "567                 2.219635  \n",
       "568                -0.751207  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Normalized Input Dataset:')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup (kernel, hyper-parameters)\n",
    "def model_setup(kernel, C = 1.0, degree = 3):\n",
    "    model = SVC(kernel=kernel, C = C, degree = degree)\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    conf_matrix = pd.DataFrame(confusion_matrix(Ytest, model.predict(Xtest)))\n",
    "    train_score = round(100*model.score(Xtrain, Ytrain),2)\n",
    "    test_score = round(100*model.score(Xtest, Ytest),2)\n",
    "    recall = round(100*recall_score(Ytest, model.predict(Xtest)),2)\n",
    "    precision = round(100*precision_score(Ytest, model.predict(Xtest)),2)\n",
    "    return conf_matrix, train_score, test_score, recall, precision\n",
    "\n",
    "def result_printout(kernel, C_vals, degree = 3):\n",
    "    print(kernel.title(), 'kernel model\\n________________________\\n')\n",
    "    scores = pd.DataFrame({'Scores by C-value' : ['Train','Test'] }).set_index('Scores by C-value')\n",
    "    full_conf_mat = pd.DataFrame()\n",
    "    for C in C_vals:\n",
    "        conf_matrix, train_score, test_score, recall, precision = model_setup(kernel, C, degree)\n",
    "        score = pd.DataFrame({C : [train_score, test_score, recall, precision] , 'Scores by C-value' : ['Train','Test','Recall','Precision']}).set_index('Scores by C-value')\n",
    "        scores = pd.concat([scores,score], axis = 1)\n",
    "        print('\\nConfusion Matrix: C =',C,'\\n',conf_matrix)\n",
    "    print('\\n________________________\\n\\nAccuracy Scores:')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear kernel model\n",
      "________________________\n",
      "\n",
      "\n",
      "Confusion Matrix: C = 0.1 \n",
      "     0    1\n",
      "0  60    3\n",
      "1   2  106\n",
      "\n",
      "Confusion Matrix: C = 1 \n",
      "     0    1\n",
      "0  61    2\n",
      "1   5  103\n",
      "\n",
      "Confusion Matrix: C = 10 \n",
      "     0    1\n",
      "0  59    4\n",
      "1   7  101\n",
      "\n",
      "Confusion Matrix: C = 100 \n",
      "     0    1\n",
      "0  59    4\n",
      "1   6  102\n",
      "\n",
      "________________________\n",
      "\n",
      "Accuracy Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores by C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>98.74</td>\n",
       "      <td>98.74</td>\n",
       "      <td>99.25</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>97.08</td>\n",
       "      <td>95.91</td>\n",
       "      <td>93.57</td>\n",
       "      <td>94.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>98.15</td>\n",
       "      <td>95.37</td>\n",
       "      <td>93.52</td>\n",
       "      <td>94.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>97.25</td>\n",
       "      <td>98.10</td>\n",
       "      <td>96.19</td>\n",
       "      <td>96.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1    1.0    10.0    100.0\n",
       "Scores by C-value                             \n",
       "Train              98.74  98.74  99.25  100.00\n",
       "Test               97.08  95.91  93.57   94.15\n",
       "Recall             98.15  95.37  93.52   94.44\n",
       "Precision          97.25  98.10  96.19   96.23"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernels = ['linear','rbf','poly','sigmoid']\n",
    "C_vals = [0.10, 1, 10, 100]\n",
    "result_printout('linear', C_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear kernel performance\n",
    "Performance on the training set increased as C increased (as expected). However, the highest testing score (of the C-values used) was found for C=0.10. Even though C=0.10 had the lowest training score, it appears to be the best option for generalizing to testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rbf kernel model\n",
      "________________________\n",
      "\n",
      "\n",
      "Confusion Matrix: C = 0.1 \n",
      "     0    1\n",
      "0  55    8\n",
      "1   3  105\n",
      "\n",
      "Confusion Matrix: C = 1 \n",
      "     0    1\n",
      "0  60    3\n",
      "1   1  107\n",
      "\n",
      "Confusion Matrix: C = 10 \n",
      "     0    1\n",
      "0  62    1\n",
      "1   1  107\n",
      "\n",
      "Confusion Matrix: C = 100 \n",
      "     0    1\n",
      "0  63    0\n",
      "1   5  103\n",
      "\n",
      "________________________\n",
      "\n",
      "Accuracy Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores by C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>95.23</td>\n",
       "      <td>98.24</td>\n",
       "      <td>98.74</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>93.57</td>\n",
       "      <td>97.66</td>\n",
       "      <td>98.83</td>\n",
       "      <td>97.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>97.22</td>\n",
       "      <td>99.07</td>\n",
       "      <td>99.07</td>\n",
       "      <td>95.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>92.92</td>\n",
       "      <td>97.27</td>\n",
       "      <td>99.07</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1    1.0    10.0    100.0\n",
       "Scores by C-value                             \n",
       "Train              95.23  98.24  98.74  100.00\n",
       "Test               93.57  97.66  98.83   97.08\n",
       "Recall             97.22  99.07  99.07   95.37\n",
       "Precision          92.92  97.27  99.07  100.00"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernels = ['linear','rbf','poly','sigmoid']\n",
    "C_vals = [0.10, 1, 10, 100]\n",
    "result_printout('rbf', C_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel Performance\n",
    "For C=10, RBF reached a higher testing score than any other tested parameter of the Linear kernel. Preceision and Recall were also significantly higher (~99%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: DF = 3\n",
      "Poly kernel model\n",
      "________________________\n",
      "\n",
      "\n",
      "Confusion Matrix: C = 0.1 \n",
      "     0    1\n",
      "0  33   30\n",
      "1   1  107\n",
      "\n",
      "Confusion Matrix: C = 1 \n",
      "     0    1\n",
      "0  46   17\n",
      "1   2  106\n",
      "\n",
      "Confusion Matrix: C = 10 \n",
      "     0    1\n",
      "0  59    4\n",
      "1   1  107\n",
      "\n",
      "Confusion Matrix: C = 100 \n",
      "     0    1\n",
      "0  60    3\n",
      "1   2  106\n",
      "\n",
      "________________________\n",
      "\n",
      "Accuracy Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores by C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>83.92</td>\n",
       "      <td>89.70</td>\n",
       "      <td>96.73</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>81.87</td>\n",
       "      <td>88.89</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>99.07</td>\n",
       "      <td>98.15</td>\n",
       "      <td>99.07</td>\n",
       "      <td>98.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>78.10</td>\n",
       "      <td>86.18</td>\n",
       "      <td>96.40</td>\n",
       "      <td>97.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1    1.0    10.0   100.0\n",
       "Scores by C-value                            \n",
       "Train              83.92  89.70  96.73  99.25\n",
       "Test               81.87  88.89  97.08  97.08\n",
       "Recall             99.07  98.15  99.07  98.15\n",
       "Precision          78.10  86.18  96.40  97.25"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernels = ['linear','rbf','poly','sigmoid']\n",
    "C_vals = [0.10, 1, 10, 100]\n",
    "print('NOTE: DF = 3')\n",
    "result_printout('poly', C_vals, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: DF = 5\n",
      "Poly kernel model\n",
      "________________________\n",
      "\n",
      "\n",
      "Confusion Matrix: C = 0.1 \n",
      "     0    1\n",
      "0  25   38\n",
      "1   2  106\n",
      "\n",
      "Confusion Matrix: C = 1 \n",
      "     0    1\n",
      "0  32   31\n",
      "1   1  107\n",
      "\n",
      "Confusion Matrix: C = 10 \n",
      "     0    1\n",
      "0  39   24\n",
      "1   1  107\n",
      "\n",
      "Confusion Matrix: C = 100 \n",
      "     0    1\n",
      "0  54    9\n",
      "1   2  106\n",
      "\n",
      "________________________\n",
      "\n",
      "Accuracy Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores by C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>78.89</td>\n",
       "      <td>86.68</td>\n",
       "      <td>90.20</td>\n",
       "      <td>94.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>76.61</td>\n",
       "      <td>81.29</td>\n",
       "      <td>85.38</td>\n",
       "      <td>93.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>98.15</td>\n",
       "      <td>99.07</td>\n",
       "      <td>99.07</td>\n",
       "      <td>98.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>73.61</td>\n",
       "      <td>77.54</td>\n",
       "      <td>81.68</td>\n",
       "      <td>92.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1    1.0    10.0   100.0\n",
       "Scores by C-value                            \n",
       "Train              78.89  86.68  90.20  94.72\n",
       "Test               76.61  81.29  85.38  93.57\n",
       "Recall             98.15  99.07  99.07  98.15\n",
       "Precision          73.61  77.54  81.68  92.17"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernels = ['linear','rbf','poly','sigmoid']\n",
    "C_vals = [0.10, 1, 10, 100]\n",
    "print('NOTE: DF = 5')\n",
    "result_printout('poly', C_vals, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: DF = 10\n",
      "Poly kernel model\n",
      "________________________\n",
      "\n",
      "\n",
      "Confusion Matrix: C = 0.1 \n",
      "     0    1\n",
      "0  18   45\n",
      "1   2  106\n",
      "\n",
      "Confusion Matrix: C = 1 \n",
      "     0    1\n",
      "0  26   37\n",
      "1   3  105\n",
      "\n",
      "Confusion Matrix: C = 10 \n",
      "     0    1\n",
      "0  30   33\n",
      "1   8  100\n",
      "\n",
      "Confusion Matrix: C = 100 \n",
      "     0   1\n",
      "0  29  34\n",
      "1  12  96\n",
      "\n",
      "________________________\n",
      "\n",
      "Accuracy Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores by C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>77.64</td>\n",
       "      <td>81.41</td>\n",
       "      <td>85.68</td>\n",
       "      <td>89.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>72.51</td>\n",
       "      <td>76.61</td>\n",
       "      <td>76.02</td>\n",
       "      <td>73.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>98.15</td>\n",
       "      <td>97.22</td>\n",
       "      <td>92.59</td>\n",
       "      <td>88.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>70.20</td>\n",
       "      <td>73.94</td>\n",
       "      <td>75.19</td>\n",
       "      <td>73.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1    1.0    10.0   100.0\n",
       "Scores by C-value                            \n",
       "Train              77.64  81.41  85.68  89.20\n",
       "Test               72.51  76.61  76.02  73.10\n",
       "Recall             98.15  97.22  92.59  88.89\n",
       "Precision          70.20  73.94  75.19  73.85"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernels = ['linear','rbf','poly','sigmoid']\n",
    "C_vals = [0.10, 1, 10, 100]\n",
    "print('NOTE: DF = 10')\n",
    "result_printout('poly', C_vals, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly Kernel Performance (DOF = 3, 5, 10)\n",
    "For DOF = 3, performance was highest for C=10. Interestingly, performance for DOF = 5 was highest for C = 100. For both DOF = 5 & 10, Precision metrics were generally quite low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid kernel model\n",
      "________________________\n",
      "\n",
      "\n",
      "Confusion Matrix: C = 0.1 \n",
      "     0    1\n",
      "0  55    8\n",
      "1   2  106\n",
      "\n",
      "Confusion Matrix: C = 1 \n",
      "     0    1\n",
      "0  58    5\n",
      "1   5  103\n",
      "\n",
      "Confusion Matrix: C = 10 \n",
      "     0   1\n",
      "0  58   5\n",
      "1  13  95\n",
      "\n",
      "Confusion Matrix: C = 100 \n",
      "     0   1\n",
      "0  55   8\n",
      "1  13  95\n",
      "\n",
      "________________________\n",
      "\n",
      "Accuracy Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores by C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>94.97</td>\n",
       "      <td>95.23</td>\n",
       "      <td>93.97</td>\n",
       "      <td>93.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>94.15</td>\n",
       "      <td>94.15</td>\n",
       "      <td>89.47</td>\n",
       "      <td>87.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>98.15</td>\n",
       "      <td>95.37</td>\n",
       "      <td>87.96</td>\n",
       "      <td>87.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>92.98</td>\n",
       "      <td>95.37</td>\n",
       "      <td>95.00</td>\n",
       "      <td>92.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1    1.0    10.0   100.0\n",
       "Scores by C-value                            \n",
       "Train              94.97  95.23  93.97  93.97\n",
       "Test               94.15  94.15  89.47  87.72\n",
       "Recall             98.15  95.37  87.96  87.96\n",
       "Precision          92.98  95.37  95.00  92.23"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernels = ['linear','rbf','poly','sigmoid']\n",
    "C_vals = [0.10, 1, 10, 100]\n",
    "result_printout('sigmoid', C_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Kernel Performance\n",
    "Across all metrics used, the Sigmoid Kernel performed best for lower C values. \n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Overall, the top performing model (of the models tested) was RBF for C = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_CNk7CCDBZW"
   },
   "source": [
    "## Exercise three [OPTIONAL]\n",
    "\n",
    "*Try to solve this as an optional assignement, we will review the code in the following class*\n",
    "\n",
    "Support vector machines (SVMs) are a particularly powerful and flexible class of supervised algorithms. In this exercise, we will develop the intuition behind support vector machines and their use in classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DI8A79SnDBZa"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "man6HsMEDBZe"
   },
   "source": [
    "To begin with, let us generate the data for a linear classification problem. In order to do so use the `make_blobs` function from `sklearn`. We want to generate 50 samples, set the `random_state=0` and `cluster_std=0.6`. Finally plot the points with `plt.scatter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUqAe-pRDBZf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IjYXDIVDBZi"
   },
   "source": [
    "A linear discriminative classifier would attempt to draw a straight line separating the two sets of data, and thereby create a model for classification. For two dimensional data like that shown here, this is a task we could do by hand. Think about a line that separates the two classes, how many are there? Which do you think would be the more appropiate given the data points? Draw some lines over this plot with slopes [1, 0.5, -0.2] and biases [0.65, 1.6, 2.9]. Use the `np.linespace` function to generate the x and the line equation \n",
    "\n",
    "$$y = mx + b$$\n",
    "\n",
    "for the y. Finally plot a \"new point\" in the coordinates (0.6, 2.1) with a red X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlK4-WhqDBZj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPmh31QGDBZm"
   },
   "source": [
    "## SVM margins and support vectors\n",
    "These are three very different separators which, nevertheless, perfectly discriminate between these samples. Depending on which you choose, a new data point (e.g., the one marked by the \"X\" in this plot) will be assigned a different label!.\n",
    "\n",
    "Support vector machines offer one way to improve on this. The intuition is this: rather than simply drawing a line between the classes, we can draw around each line a margin of some width, up to the nearest point (no matter the class). To visualize this, let us repeat the same plot but adding some code to fill the margins. Use the method `plt.fill_between` with `color='#AAAAAA'`. The margins for each of the lines above are [0.33, 0.55, 0.2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pU89a8OxDBZn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfCWQ4iNDBZq"
   },
   "source": [
    "Now fit an SVM to this data. Use Scikit-Learn's support vector classifier to train an SVM model. For the time being, we will use a linear kernel and set the C parameter to a very large number like 1E10. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSNunBV7DBZr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PezkPYL6DBZt"
   },
   "source": [
    "Now retrieve the support vectors from the learned model. Would you be able to identify them on the plot? Why are these the support vectors? Why are they important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVi6El7fDBZu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LpWuo3Y2DBZx"
   },
   "source": [
    "This function will plot the decision boundaries of a model and the support vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRwkHIUHDBZy"
   },
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    # plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=300, linewidth=1, facecolors='none',\n",
    "                   edgecolors='blue')\n",
    "        \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWrOwVyDBZ0"
   },
   "source": [
    "Generate a scatter plot of the data set and use the previous function to draw the support vectors and the decision boundaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UjwQEmtDBZ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uysvg21VDBZ4"
   },
   "source": [
    "A key to this classifier's success is that for the fit, only the position of the support vectors matter; any points further from the margin which are on the correct side do not modify the fit! Technically, this is because these points do not contribute to the loss function used to fit the model, so their position and number do not matter so long as they do not cross the margin.\n",
    "\n",
    "In order to see an example of this, simulate the points with the same random seed, but now simulate 120. Then train again the SVM and plot the decision boundaries. Which are the support vectors this time? Is this an expected result? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lb5vprHPDBZ5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3iHukpeDBZ7"
   },
   "source": [
    "## SVM softening the margins\n",
    "Now add a new point which is inside the decision boundary, say (-0.5, 2) to class 0, what do you expect will happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xUDN6uIeDBZ8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KY4n1jerDBZ_"
   },
   "source": [
    "How about adding an even more outlier, like (0, 0) to class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxD0OxVXDBaA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mL4375vTDBaC"
   },
   "source": [
    "What happened to the margin? Could we use this model if we had a red point further right? Why?\n",
    "\n",
    "Now, is there a way that we could try to make the SVM more robust to these possible outliers? Which one? Try to implement an SVM model with the same data modifying the C parameter. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLkzsKUjDBaD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQHsrz0xDBaG"
   },
   "source": [
    "## SVM Kernels\n",
    "Now we have seen that SVM are very useful to find the optimal separating hyper-plane when your data is linearly separable. Even when you have some noise in the data set, you can tune the C-value to be able to adjust this. But what happens if your classes are not linearly separable? Is there a way we could overcome this draw-back? Let us generate a dataset that is not linearly separable. Use the `make_circles` method from `samples_generator` in sklearn. Generate 100 examples with `factor=.1, noise=.1, random_state=0`. Then generate a scatter plot to visualize the samples, use a different color for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InJwc2mXDBaH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yn6JyRfDBaJ"
   },
   "source": [
    "Now try to classify this data with a linear SVM, what do you expect will happen? Does this model capture the pattern of the classes? Plot the classification results with the `plot_svc_decision_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8bOMWVdSDBaK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GcgCa72_DBaN"
   },
   "source": [
    "What could we do in order to make this dataset linearly separable? We can project it into a higher dimensional space. Note the similarity between this, and the polynomial regression. In order to have a better understanding of how kernels work, first implement a third axis with python with the following expression:\n",
    "\n",
    "$$x_3 = e^{-(x_1^2 + x_2^2)}$$\n",
    "\n",
    "Actually this is somewhat equivalent to the rbf kernel. You should name the new axis `x_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o45PISlODBaN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HiAyuCCEDBaQ"
   },
   "source": [
    "Once you have implemented this 3rd axis, you may "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpDOj7ffDBaR"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "def plot_3D(elev=30, azim=30, X=X, y=y):\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter3D(X[:, 0], X[:, 1], x_3, c=y, s=50, cmap='autumn')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('x_1')\n",
    "    ax.set_ylabel('x_2')\n",
    "    ax.set_zlabel('x_3')\n",
    "    \n",
    "interact(plot_3D, elev=[30, 0, 90], azip=(-180, 180),\n",
    "         X=fixed(X), y=fixed(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4rJsRTQyDBaV"
   },
   "source": [
    "Now use the SVM classifier but set the `kernel='rbf'` with high value for C and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uw5G5p5DDBaW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEexYnN1DBae"
   },
   "source": [
    "## Evaluating the classification results\n",
    "In order to assess the goodness of our model we need to compute some quantitative scores, we will review some of the most relevant. First, use the function `make_blobs` to generate a multilabel dataset. Generate 200 samples with 4 different classes set `random_state=0` and `cluster_std=0.6` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwvy5D0_DBag"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oA2vO9MUDBai"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-VV9ldrDBak"
   },
   "source": [
    "Split the data set in training and test and apply the SVC with `C=1, kernel='rbf', gamma='auto', class_weight='balanced', decision_function_shape='ovr'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XI3eDREDBal"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "heL4lVD5DBao"
   },
   "source": [
    "Predict on the test set and plot the confusion matrix, use the `confusion_matrix` function from sklearn and `heatmap` from seaborn. What would be the confusion matrix result of a perfect classification? What information can we extract from it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lbRXQg3DBao"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GWVAc9PDBar"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sL_fpv4dDBat"
   },
   "source": [
    "Finally compute the accuracy score, what does this value mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oT3eCLRwDBat"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oWiIwsYeDBav"
   },
   "source": [
    "You can use the follwing code to visualize the decision function computed by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQYhjHVODBaw"
   },
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "X0, X1 = Xtest[:, 0], Xtest[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "plot_contours(svc, xx, yy,\n",
    "               cmap='jet', alpha=0.6)\n",
    "\n",
    "plt.scatter(X0, X1, c=ytest, cmap='jet', s=20, edgecolors='k')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRxrK8DqDBaz"
   },
   "source": [
    "Now repeat the computations with a linear kernel, what changes do you observe? Now change the `cluster_std` when you generate the data, what would you expecte when you increase it? and when you decrease it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBUs9YaOAEBs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Session_5_Classical_Data_Analysis_SVM_EXERCISES.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
